# -*- coding: utf-8 -*-
"""ant_q_walks_train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19Za8h-GjhxWDEsf7dZeV11K5etXJLLwf
"""

'''
Parameters:
1. Graph
2. Number of episodes
3. Number of threads
4. Max number of bots
5. algo_name == 'ant_q_tsp'
6. random_string

Outputs:
1. 'random_string'_vis.html - Visualization of optimal cycle across episodes
2. 'random_string'_seq.in - sequence of node visits
'''

!pip install networkx

import networkx as nx
import sys, os
import random as rn
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

"""# **Random testing**"""

# bipartite graph
n = 3
a = ['a{}'.format(i) for i in range(n)]
b = ['b{}'.format(j) for j in range(n)]

a.append('d')
b.append('s')

g_temp = nx.DiGraph()
g_temp.add_nodes_from(a, bipartite='end')
g_temp.add_nodes_from(b, bipartite='current')

for i in range(n):
    for j in range(n):
        ai, bj = "a{}".format(i), "b{}".format(j)
        if ai != 'd' and bj != 's':
            g_temp.add_edge(bj, ai, capacity=1.0)
            g_temp[bj][ai]['name'] = '{}_to_{}'.format(bj, ai)
            g_temp[bj][ai]['length'] = (i+j)+1

for ai in a:
    if ai != 'd':
        g_temp.add_edge(ai, 'd', capacity=1.0)
        g_temp[ai]['d']['name'] = '{}_to_d'.format(ai)
        g_temp[ai]['d']['length'] = 100

for bj in b:
    if bj != 's':
        g_temp.add_edge('s', bj, capacity=1.0)
        g_temp['s'][bj]['name'] = 's_to_{}'.format(bj)
        g_temp['s'][bj]['length'] = 100

nx.draw(g_temp, with_labels=True)

# original graph
n = 6
a = ['a{}'.format(i) for i in range(n)]
b = ['b{}'.format(j) for j in range(n)]

og_temp = nx.Graph()
og_temp.add_nodes_from(a)
og_temp.add_nodes_from(b)

for i in range(n):
    for j in range(n):
        ai, bj = "a{}".format(i), "b{}".format(j)
        if ai != 'd' and bj != 's':
            og_temp.add_edge(bj, ai, capacity=1.0)
            og_temp[bj][ai]['name'] = '{}_to_{}'.format(bj, ai)
            og_temp[bj][ai]['length'] = (i+j)+1

nx.draw(og_temp, with_labels=True)

nx.maximum_flow_value(g_temp, 's', 'd')

def create_biGraph(curr_nodes, des_nodes, org_graph):
    # bipartite graph
    n = len(curr_nodes)

    b = curr_nodes.copy()
    a = des_nodes.copy()

    b.append('s')
    a.append('d')

    g_temp = nx.DiGraph()
    g_temp.add_nodes_from(a, bipartite='end')
    g_temp.add_nodes_from(b, bipartite='current')

    for ai in a:
        for bj in b:
            if ai != 'd' and bj != 's':
                g_temp.add_edge(bj, ai, capacity=1.0)
                g_temp[bj][ai]['name'] = '{}_to_{}'.format(bj, ai)
                g_temp[bj][ai]['length'] = org_graph[ai][bj]["length"]

    # add edges from a to d - length = 100 units
    for ai in a:
        if ai != 'd':
            g_temp.add_edge(ai, 'd', capacity=1.0)
            g_temp[ai]['d']['name'] = '{}_to_d'.format(ai)
            g_temp[ai]['d']['length'] = 100

    # add edges from s to b - length = 100 units
    for bj in b:
        if bj != 's':
            g_temp.add_edge('s', bj, capacity=1.0)
            g_temp['s'][bj]['name'] = 's_to_{}'.format(bj)
            g_temp['s'][bj]['length'] = 100
    
    return g_temp

def return_to_base(bi_g, org_graph, le):
    curr_nodes = [n for n, d in bi_g.nodes(data=True) if d["bipartite"] == 'current']
    des_nodes = [n for n, d in bi_g.nodes(data=True) if d["bipartite"] == 'end']
    curr_nodes.remove('s')
    des_nodes.remove('d')

    print("current nodes: {}".format(curr_nodes))
    print("destination nodes: {}".format(des_nodes))    

    # copy the bipartite graph
    bi_g_copy = bi_g.copy()

    # create a list of final walk lengths
    num_a = len(curr_nodes)
    walks = []

    for i in range(num_a):
        for j in range(num_a):
            b_node, a_node = 'b{}'.format(i), 'a{}'.format(j)
            le_temp = le[i] + org_graph[b_node][a_node]["length"]
            walks.append(["{}_{}".format(b_node, a_node), le_temp])
    
    # sort the walk lengths and indices
    walks.sort(key = lambda walks: walks[1])
    walks = walks[::-1]
    walks_copy = walks.copy()
    names, walk_lens = map(list, zip(*walks))

    print("walks list: {}".format(walks))
    # iterate over all the edges
    for w in walks_copy:
        cn, dn = w[0].split("_")
        edge_len = bi_g_copy[cn][dn]["length"]
        edge_name = "{}_{}".format(cn, dn)

        bi_g_copy.remove_edge(cn, dn)
        if nx.maximum_flow_value(bi_g_copy, 's', 'd') >= num_a:
            ind = names.index(edge_name)
            names.pop(ind)
            walks.pop(ind)
            walk_lens.pop(ind)
        elif nx.maximum_flow_value(bi_g_copy, 's', 'd') < num_a:
            bi_g_copy.add_edge(cn, dn, capacity=1.0)
            bi_g_copy[cn][dn]['name'] = edge_name
            bi_g_copy[cn][dn]['length'] = edge_len

        print("{} --> {} done".format(cn ,dn))
    return walks

# bigraph
graph1 = g_temp.copy()
# original graph
graph2 = og_temp.copy()
# walk lens till now
lens = [6, 11, 3]

final_walks = return_to_base(graph1, graph2, lens)

print(final_walks)

lsd = [2, 3, 1, 56, 3]
ind = list(np.argsort(lsd))
ind.reverse()
print(ind)
lsd = list(np.sort(lsd)[::-1])
print(type(lsd))
print(lsd)

test_list = [['b0_a0', 2], ['b0_a1', 11], ['b1_a0', 5], ['b1_a1', 1]]
 
# printing original list
print ("The original list is : " + str(test_list))
 
# sort list of list
# sort by second index
test_list.sort(key = lambda test_list: test_list[1])
print(test_list)

le_temp = {}
le_temp['b1_a1'] = 100
le_temp['b1_a2'] = 200
le_temp['b2_a1'] = 300
le_temp['b2_a2'] = 400

arr_temp = np.zeros(shape=(2,2))
arr_temp[0][0] = 0
arr_temp[0][1] = 1
arr_temp[1][0] = 2
arr_temp[1][1] = 3
print(arr_temp)

ind_temp = np.argsort(arr_temp)
ind_temp

for i in range(2):
    for j in range(2):
        i = ind_temp[i][j]
        print(arr_temp[ind_temp[i][j]][ind_temp[j]])

le_test = ['b2', 'b0', 'b1']
le_test.sort()
print(le_test)

"""# **Ant-Q**"""

class Ant_Q:

    def __init__(self, graph, num_threads, init_nodes, sim_dir, q_0 = 0.8, alpha = 0.1, gamma = 0.3, delta = 3, beta = 0, W = 10000):
        
        self.graph = graph.copy()
        self.edges_og = list(graph.edges())
        self.nodes = list(graph.nodes())
        self.paths = {}
        self.num_threads = min(num_threads, len(self.nodes))
        # building complete graph
        for i in self.nodes:
            for j in self.nodes:
                if i != j and not (i, j) in self.edges_og:
                    self.graph.add_edge(i, j)
                    self.graph[i][j]['name'] = '{}to{}'.format(i, j)
                    self.graph[i][j]['length'] = nx.dijkstra_path_length(graph, i, j, 'length')
                    self.paths[(i, j)] = nx.dijkstra_path(graph, i, j, 'length')
                elif i==j and not (i, j) in self.graph.edges():
                    self.graph.add_edge(i, j)
                    self.graph[i][j]['name'] = '{}to{}'.format(i, j)
                    self.graph[i][j]['length'] = 0
                elif i != j:
                    self.paths[(i, j)] = [i, j]

        self.edges = list(self.graph.edges())
        self.lengths = [float(self.graph[e[0]][e[1]]['length']) for e in self.edges]

        avg_len = sum(self.lengths)/len(self.edges)
        max_len = max(self.lengths)
        for e in self.edges:
            if e[0]!=e[1]:
                self.graph[e[0]][e[1]]['h_value'] = max_len/float(self.graph[e[0]][e[1]]['length'])
                self.graph[e[0]][e[1]]['q_value'] = max_len/(avg_len)
            elif e[0]==e[1]:
                self.graph[e[0]][e[1]]['h_value'] = 0
                self.graph[e[0]][e[1]]['q_value'] = 0

        self.q = q_0
        self.q_rem = 1 - q_0
        self.alpha = alpha
        self.beta = beta
        self.gamma = gamma
        self.delta = delta
        self.W = W

        self.init_nodes = init_nodes.copy()
        self.num_agents = len(self.init_nodes)      # num of agents = num_init_nodes
        self.agents = [i for i in range(self.num_agents)]
        self.best_walk = []
        self.best_len = np.inf
        self.best_walk_directions = []
        self.best_walk_edges = []

        self.sim_dir = sim_dir

    def run(self):
        actions = self.nodes.copy()
        actions = list(set(actions).difference(set(self.init_nodes)))

        walk_so_far = [[self.init_nodes[i]] for i in self.agents]                            # it will be a list of lists of size num_agents == num_init_nodes
        
        cur_nodes = self.init_nodes.copy()
        
        while len(actions) != 0:
            values = []
            max_vals = []

            for a in self.agents:
                value_list = [(self.graph[cur_nodes[a]][node]['q_value'] ** self.delta) * (self.graph[cur_nodes[a]][node]['h_value'] ** self.beta) for node in actions]                    
                values.append(value_list)
                max_vals.append(max(value_list))

            a_ind = np.argmax(max_vals)                     # agent which has the max q_value
            a_node = actions[np.argmax(values[a_ind])]               # node which has the max q_value for this agent

            # values = [self.graph[cur_node][node]['q_value'] for node in actions]
            
            if rn.random() <= self.q:
                node = str(a_node)

            else:
                # sample a random angent (uniformly)
                a_ind = rn.randint(int(self.init_nodes[0]), int(self.init_nodes[-1]))
                tot_val = sum(values[a_ind])

                a_values = [v/tot_val for v in values[a_ind]]
                #random-proportional
                r_val = rn.random()
                cum_sum = 0.
                i = -1
                while r_val < cum_sum:
                    i += 1
                    cum_sum += a_values[i]
                node = str(actions[i])
                
            walk_so_far[a_ind].append(node)
            actions.remove(node)
            
            # update Q_values after the action taken
            if actions != []:
                next_val = max([self.graph[node][nex]['q_value'] for nex in actions])
                self.graph[cur_nodes[a_ind]][node]['q_value'] *= (1 - self.alpha)
                self.graph[cur_nodes[a_ind]][node]['q_value'] += self.alpha * self.gamma * next_val
            
            cur_nodes[a_ind] = node

        # return to the base
        actions = self.init_nodes.copy()
        agents_return = self.agents.copy()

        while len(actions) != 0:
            values = []
            max_vals = []

            for a in agents_return:
                value_list = []
                for node in actions:
                    value_list.append((self.graph[cur_nodes[a]][node]['q_value'] ** self.delta) * (self.graph[cur_nodes[a]][node]['h_value'] ** self.beta))                   
                values.append(value_list)
                max_vals.append(max(value_list))

            ind = np.argmax(max_vals)                     # agent which has the max q_value
            
            a_ind = agents_return[ind]
            a_node = actions[np.argmax(values[ind])]               # node which has the max q_value for this agent
            node = str(a_node)
                
            walk_so_far[a_ind].append(node)
            actions.remove(node)
            agents_return.remove(a_ind)
            
            cur_nodes[a_ind] = node

        le = []
        for a in self.agents:
            walk = walk_so_far[a]
            agent_l = 0
            for i in range(len(walk)-1):
                agent_l += self.graph[walk[i]][walk[i + 1]]['length']
            le.append(agent_l)

        return (walk_so_far, le)
    
    def episode(self, ep_count):
        
        if ep_count > 100 and self.q < 0.95:
            self.q += (self.q_rem/2) ** 2
            self.q_rem = 1 - self.q 
        
        # takes actions -> till all nodes have been covered -> return back -> \\ return the walks of the agents and their lengths as lists
        walks, lengths = self.run()

        worst_idleness = max(lengths)

        # we need to use the worst path since it indicates worst idleness of our patrolling --- not iter_best --> iter_worst 
        del_aq = self.W / worst_idleness

        for w in walks:
            for i in range(len(w) - 1):
                e0, e1 = w[i], w[i+1]
                if e0 != e1:
                    self.graph[e0][e1]['q_value'] += self.alpha * del_aq

        return (walks, worst_idleness)

if __name__ == '__main__':
    
    now = datetime.now()
    date_time = now.strftime("%m_%d_%Y_%H%M%S")
    
    # for current purposes only
    params = {
        "graph": "/content/drive/MyDrive/SEM - 7/MRPP/graph_ml/grid_5_5.graphml",
        "num_episodes": 10000,
        "num_threads": 1,
        "init_nodes": ['0', '1', '2'],
        "algo_name": "ant_q_tsp",
        "random_string": date_time,
        "output_path": "/content/drive/MyDrive/SEM - 7/MRPP/outputs",
    }

    graph_name = params['graph']
    num_episodes = params['num_episodes']
    num_threads = params['num_threads']                 # this is = 1 in our case
    init_nodes = params['init_nodes']
    algo = params['algo_name']
    sim_name = params['random_string']
    sim_dir = params["output_path"]

    log_data = True

    # os.mkdir(sim_dir)

    if algo != 'ant_q_tsp':
        print('Not this algorithm')
        exit

    g = nx.read_graphml(graph_name)
    lengths = []

    # best_walk = test.best_walk_directions
    with open(sim_dir + '/{}.txt'.format(sim_name), 'w') as f:
        test = Ant_Q(g, num_threads, init_nodes, sim_dir)

        for i in range(num_episodes):
            print("episode: {}".format(i))
            w, l = test.episode(i + 1)
            lengths.append(l)

            if log_data == True:
                f.write('Epsiode' + str(i + 1) + ': ' + str(l) + '\n')
                f.write('\n')
                for n in w:
                    f.write(str(n)+ '\n')
                f.write('\n')

    x_axis = [i for i in range(num_episodes)]
    plt.figure(figsize=(10,8))
    plt.plot(x_axis, lengths)
    plt.title("train_error error")
    plt.show()

